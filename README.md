# Llama model list 
(foxer_env) chwenjun225@DESKTOP-B8RSUBM:~/projects/foxer$ pip install llama-stack
(foxer_env) chwenjun225@DESKTOP-B8RSUBM:~/projects/foxer$ llama model list --show-all
+-----------------------------------------+-----------------------------------------------------+----------------+
| Model Descriptor                        | Hugging Face Repo                                   | Context Length |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-7b                              | meta-llama/Llama-2-7b                               | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-13b                             | meta-llama/Llama-2-13b                              | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-70b                             | meta-llama/Llama-2-70b                              | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-7b-chat                         | meta-llama/Llama-2-7b-chat                          | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-13b-chat                        | meta-llama/Llama-2-13b-chat                         | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-2-70b-chat                        | meta-llama/Llama-2-70b-chat                         | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-3-8B                              | meta-llama/Llama-3-8B                               | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-3-70B                             | meta-llama/Llama-3-70B                              | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-3-8B-Instruct                     | meta-llama/Llama-3-8B-Instruct                      | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-3-70B-Instruct                    | meta-llama/Llama-3-70B-Instruct                     | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-8B                             | meta-llama/Llama-3.1-8B                             | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-70B                            | meta-llama/Llama-3.1-70B                            | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B:bf16-mp8                  | meta-llama/Llama-3.1-405B                           | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B                           | meta-llama/Llama-3.1-405B-FP8                       | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B:bf16-mp16                 | meta-llama/Llama-3.1-405B                           | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-8B-Instruct                    | meta-llama/Llama-3.1-8B-Instruct                    | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-70B-Instruct                   | meta-llama/Llama-3.1-70B-Instruct                   | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B-Instruct:bf16-mp8         | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B-Instruct                  | meta-llama/Llama-3.1-405B-Instruct-FP8              | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.1-405B-Instruct:bf16-mp16        | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-1B                             | meta-llama/Llama-3.2-1B                             | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-3B                             | meta-llama/Llama-3.2-3B                             | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-11B-Vision                     | meta-llama/Llama-3.2-11B-Vision                     | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-90B-Vision                     | meta-llama/Llama-3.2-90B-Vision                     | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-1B-Instruct                    | meta-llama/Llama-3.2-1B-Instruct                    | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-3B-Instruct                    | meta-llama/Llama-3.2-3B-Instruct                    | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-1B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8     | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-1B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8 | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-3B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8     | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-3B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8 | 8K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-11B-Vision-Instruct            | meta-llama/Llama-3.2-11B-Vision-Instruct            | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.2-90B-Vision-Instruct            | meta-llama/Llama-3.2-90B-Vision-Instruct            | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama3.3-70B-Instruct                   | meta-llama/Llama-3.3-70B-Instruct                   | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-3-11B-Vision                | meta-llama/Llama-Guard-3-11B-Vision                 | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-3-1B:int4                   | meta-llama/Llama-Guard-3-1B-INT4                    | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-3-1B                        | meta-llama/Llama-Guard-3-1B                         | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-3-8B                        | meta-llama/Llama-Guard-3-8B                         | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-3-8B:int8                   | meta-llama/Llama-Guard-3-8B-INT8                    | 128K           |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Llama-Guard-2-8B                        | meta-llama/Llama-Guard-2-8B                         | 4K             |
+-----------------------------------------+-----------------------------------------------------+----------------+
| Prompt-Guard-86M                        | meta-llama/Prompt-Guard-86M                         | 2K             |
+-----------------------------------------+-----------------------------------------------------+----------------+

# Select a model
llama model download --source meta --model-id  MODEL_ID

# Run the model
torchrun --nproc_per_node 1 \
	chat_completion.py \
	--ckpt_dir ~/.llama/checkpoints/Llama3.1-8B-Instruct/ \
	--tokenizer_path ~/.llama/checkpoints/Llama3.1-8B-Instruct/tokenizer.model \
	--max_seq_len 512 --max_batch_size 6



Hiện tại, tôi đang tập trung nghiên cứu các mô hình ngôn ngữ nhỏ như Llama3.2-3B-Instruct với mục tiêu triển khai trên thiết bị di động, IoT và các hệ thống nhúng.

Trong tuần qua (thứ 2 đến thứ 5), sau khi quay trở lại công ty sau 2 năm du học, tôi đã hoàn thành các công việc sau:

1. Hoàn tất việc cài đặt và thiết lập môi trường làm việc trên máy tính công ty.
2. Tìm hiểu tài liệu liên quan đến cách sử dụng mô hình Llama.
3. Chạy và thực hiện suy luận (inference) trên mô hình Llama3.2-3B-Instruct.
4. Triển khai mô hình Llama3.2-3B-Instruct trên thiết bị di động Xiaomi 11T (Chipset: Snapdragon 888, RAM: 8G, Storage: 256GB).

Viết lại theo form sau:

I. Problems?

II. Technical difficulties ?

III. Solution ?

IV. Solution effects ?

V. Next Step ?

Achieved?
