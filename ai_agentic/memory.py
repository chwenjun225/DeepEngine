import os
import chromadb
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate

# ğŸ”¹ Cáº¥u hÃ¬nh API Key cho OpenAI
os.environ["OPENAI_API_KEY"] = "your_openai_api_key"

# ğŸ”¹ HÃ m khá»Ÿi táº¡o LLM (cÃ³ thá»ƒ Ä‘á»•i GPT thÃ nh mÃ´ hÃ¬nh khÃ¡c)
def get_llm():
    return OpenAI(model_name="gpt-3.5-turbo", temperature=0.3)

# ğŸ”¹ HÃ m khá»Ÿi táº¡o retriever tá»« ChromaDB
def get_retriever(collection_name="state_of_the_union", persist_directory="./chroma_db"):
    # DÃ¹ng HuggingFace embeddings Ä‘á»ƒ tÃ¬m kiáº¿m vector
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # Táº£i dá»¯ liá»‡u tá»« ChromaDB
    vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=collection_name)

    # Sá»­ dá»¥ng retriever Ä‘á»ƒ tÃ¬m kiáº¿m dá»¯ liá»‡u gáº§n nháº¥t
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})  # ğŸ”¥ Tráº£ vá» 3 káº¿t quáº£ gáº§n nháº¥t
    return retriever

# ğŸ”¹ Táº¡o pipeline RAG
def get_rag_chain(collection_name="state_of_the_union"):
    llm = get_llm()
    retriever = get_retriever(collection_name)

    # Prompt Template Ä‘á»ƒ LLM tráº£ lá»i
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
        Báº¡n lÃ  má»™t chuyÃªn gia cÃ³ kiáº¿n thá»©c vá» chá»§ Ä‘á» nÃ y.
        DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c thÃ´ng tin tham kháº£o:
        {context}
        
        CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {question}
        Tráº£ lá»i má»™t cÃ¡ch chÃ­nh xÃ¡c dá»±a trÃªn thÃ´ng tin trÃªn.
        """
    )

    # Táº¡o chuá»—i RAG
    rag_chain = RetrievalQA(
        llm=llm,
        retriever=retriever,
        return_source_documents=True,
        prompt=prompt_template
    )
    return rag_chain

# ğŸ”¹ HÃ m cháº¡y truy váº¥n RAG
def rag_query(question, collection_name="state_of_the_union"):
    rag_chain = get_rag_chain(collection_name)
    response = rag_chain({"query": question})
    
    print("\nğŸ” **Truy váº¥n:**", question)
    print("ğŸ“– **CÃ¢u tráº£ lá»i:**", response["result"])
    print("\nğŸ“‚ **Nguá»“n dá»¯ liá»‡u sá»­ dá»¥ng:**")
    for doc in response["source_documents"]:
        print(f"- {doc.metadata['source']}: {doc.page_content[:200]}...")
    
    return response

# ğŸ”¥ Test thá»­ RAG module
if __name__ == "__main__":
    question = "Ná»™i dung chÃ­nh cá»§a bÃ i diá»…n vÄƒn lÃ  gÃ¬?"
    rag_query(question)
