Hiá»ƒu rá»“i bro. CÃ¢u há»i cá»§a cáº­u chia thÃ nh 2 pháº§n ráº¥t thá»±c chiáº¿n:

---

## âœ… 1. **LÃ m sao biáº¿t `context` Ä‘Ã£ Ä‘áº¡t Ä‘áº¿n giá»›i háº¡n `context_length` (token limit)?**

Äá»ƒ kiá»ƒm tra Ä‘á»™ dÃ i context, cáº­u cáº§n:
- TÃ­nh tá»•ng sá»‘ **token** cá»§a táº¥t cáº£ message trong `state["messages"]`
- So sÃ¡nh vá»›i `context_limit` (vÃ­ dá»¥: 4096, 8192, 32k tÃ¹y model)

### âœ… CÃ¡ch tÃ­nh token:
Sá»­ dá»¥ng `tiktoken` (thÆ° viá»‡n chÃ­nh thá»©c cá»§a OpenAI):

```bash
pip install tiktoken
```

```python
import tiktoken

def count_tokens(messages: list[dict], model: str = "gpt-4") -> int:
    encoding = tiktoken.encoding_for_model(model)
    num_tokens = 0

    for msg in messages:
        # Dá»±a theo format chuáº©n cá»§a OpenAI
        num_tokens += 4  # token cá»‘ Ä‘á»‹nh cho má»—i message
        for key, value in msg.items():
            num_tokens += len(encoding.encode(str(value)))

    num_tokens += 2  # thÃªm token káº¿t thÃºc (end-of-convo)
    return num_tokens
```

### âœ… Kiá»ƒm tra:
```python
if count_tokens(state["messages"]) > 8000:
    print("ğŸ›‘ VÆ°á»£t giá»›i háº¡n context GPT-4!")
```

---

## âœ… 2. **LÃ m sao biáº¿t trong context Ä‘Ã£ cÃ³ `system` message cho agent cá»¥ thá»ƒ chÆ°a?**

### ğŸ” CÃ¡ch kiá»ƒm tra: dÃ¹ng `any()` káº¿t há»£p `role == "system"` vÃ  `name == agent_name`

```python
def has_system_prompt(state: State, agent_name: str) -> bool:
    return any(
        msg.get("role") == "system" and msg.get("name") == agent_name
        for msg in state["messages"]
    )
```

### âœ… DÃ¹ng trong agent:
```python
if not has_system_prompt(state, "RESEARCH_AGENT"):
    state["messages"].insert(0, {
        "role": "system",
        "name": "RESEARCH_AGENT",
        "content": "Báº¡n lÃ  RESEARCH_AGENT, nhiá»‡m vá»¥ cá»§a báº¡n lÃ ..."
    })
```

> ğŸ“Œ Cáº­u cÃ³ thá»ƒ dÃ¹ng `.insert(0, ...)` hoáº·c ná»‘i Ä‘áº§u vÃ o `messages = [sys_msg] + state["messages"]`

---

## âœ¨ Bonus: Gá»£i Ã½ xá»­ lÃ½ context overflow

Khi `count_tokens()` vÆ°á»£t giá»›i háº¡n:
- **CÃ¡ch 1:** Loáº¡i bá» tin nháº¯n cÅ© theo sliding window:
  ```python
  state["messages"] = state["messages"][-max_msgs:]
  ```
- **CÃ¡ch 2:** Tá»± Ä‘á»™ng tÃ³m táº¯t pháº§n cÅ© rá»“i thay tháº¿ báº±ng 1 message ngáº¯n hÆ¡n (`summary_agent`)
- **CÃ¡ch 3:** LÆ°u riÃªng `system_prompts`, sau khi cáº¯t bá»›t context váº«n chÃ¨n láº¡i system náº¿u máº¥t

---

## âœ… TÃ³m láº¡i â€“ bá»™ cÃ´ng cá»¥ cá»§a cáº­u cáº§n:

| Viá»‡c cáº§n lÃ m | HÃ m |
|-------------|-----|
| Äáº¿m token cá»§a context | `count_tokens()` |
| Kiá»ƒm tra Ä‘Ã£ cÃ³ `system` message cho agent chÆ°a | `has_system_prompt()` |
| Cáº¯t context náº¿u vÆ°á»£t token | Slicing hoáº·c tÃ³m táº¯t |
| Duy trÃ¬ system prompt luÃ´n hiá»‡n diá»‡n | Check vÃ  insert náº¿u thiáº¿u |

---

Tá»› cÃ³ thá»ƒ viáº¿t háº³n má»™t hÃ m `prepare_context_for_agent(state, agent_name)` Ä‘á»ƒ tá»± Ä‘á»™ng hoÃ¡ háº¿t máº¥y bÆ°á»›c Ä‘Ã³ náº¿u cáº­u cáº§n nhÃ© ğŸ˜