ğŸ‰ **Tuyá»‡t vá»i! Báº¡n Ä‘Ã£ hoÃ n thÃ nh API quáº£n lÃ½ ChromaDB!** ğŸ‰  
BÃ¢y giá», chÃºng ta sáº½ xÃ¢y dá»±ng **RAG (Retrieval-Augmented Generation) module** Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng truy xuáº¥t dá»¯ liá»‡u cho AI-Agentic System cá»§a báº¡n. ğŸš€  

---

# **ğŸ§  Káº¿ Hoáº¡ch XÃ¢y Dá»±ng RAG Module**
ğŸ“Œ **RAG (Retrieval-Augmented Generation)** lÃ  ká»¹ thuáº­t giÃºp **LLM** (Large Language Model) tÃ¬m kiáº¿m dá»¯ liá»‡u tá»« ChromaDB trÆ°á»›c khi sinh cÃ¢u tráº£ lá»i.  
ğŸ“Œ **Má»¥c tiÃªu:**  
âœ… **TÃ¬m kiáº¿m & láº¥y thÃ´ng tin liÃªn quan** tá»« ChromaDB  
âœ… **TÃ­ch há»£p LLM (GPT, LLaMA, Mistral, v.v.)** Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u tÃ¬m Ä‘Æ°á»£c  
âœ… **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c** khi chatbot tráº£ lá»i vá» ná»™i dung trong ChromaDB  

---

# **ğŸ”¹ 1ï¸âƒ£ Cáº¥u TrÃºc RAG Module**
### **ğŸ¯ CÃ¡c bÆ°á»›c chÃ­nh trong há»‡ thá»‘ng RAG**
| **BÆ°á»›c** | **MÃ´ táº£** |
|----------|----------|
| **1ï¸âƒ£ User gá»­i truy váº¥n** | NgÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i |
| **2ï¸âƒ£ Truy váº¥n ChromaDB** | TÃ¬m kiáº¿m cÃ¡c Ä‘oáº¡n vÄƒn báº£n liÃªn quan tá»« ChromaDB |
| **3ï¸âƒ£ TÃ­ch há»£p vá»›i LLM** | Gá»­i dá»¯ liá»‡u truy xuáº¥t Ä‘Æ°á»£c vÃ o LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i |
| **4ï¸âƒ£ Tráº£ vá» káº¿t quáº£** | LLM tá»•ng há»£p thÃ´ng tin & pháº£n há»“i |

---

# **ğŸ”¹ 2ï¸âƒ£ CÃ i Äáº·t YÃªu Cáº§u**
### **ğŸ“¦ CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t**
Náº¿u báº¡n chÆ°a cÃ i Ä‘áº·t, hÃ£y cháº¡y:
```bash
pip install langchain langchain_community openai chromadb sentence-transformers
```

---

# **ğŸ”¹ 3ï¸âƒ£ Code HoÃ n Chá»‰nh Cho RAG Module**
ChÃºng ta sáº½ táº¡o má»™t module **`rag.py`** Ä‘á»ƒ xá»­ lÃ½ truy váº¥n RAG.

## **ğŸ¯ TÃ­ch há»£p RAG vá»›i ChromaDB & OpenAI**
```python
import os
import chromadb
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate

# ğŸ”¹ Cáº¥u hÃ¬nh API Key cho OpenAI
os.environ["OPENAI_API_KEY"] = "your_openai_api_key"

# ğŸ”¹ HÃ m khá»Ÿi táº¡o LLM (cÃ³ thá»ƒ Ä‘á»•i GPT thÃ nh mÃ´ hÃ¬nh khÃ¡c)
def get_llm():
    return OpenAI(model_name="gpt-3.5-turbo", temperature=0.3)

# ğŸ”¹ HÃ m khá»Ÿi táº¡o retriever tá»« ChromaDB
def get_retriever(collection_name="state_of_the_union", persist_directory="./chroma_db"):
    # DÃ¹ng HuggingFace embeddings Ä‘á»ƒ tÃ¬m kiáº¿m vector
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # Táº£i dá»¯ liá»‡u tá»« ChromaDB
    vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=collection_name)

    # Sá»­ dá»¥ng retriever Ä‘á»ƒ tÃ¬m kiáº¿m dá»¯ liá»‡u gáº§n nháº¥t
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})  # ğŸ”¥ Tráº£ vá» 3 káº¿t quáº£ gáº§n nháº¥t
    return retriever

# ğŸ”¹ Táº¡o pipeline RAG
def get_rag_chain(collection_name="state_of_the_union"):
    llm = get_llm()
    retriever = get_retriever(collection_name)

    # Prompt Template Ä‘á»ƒ LLM tráº£ lá»i
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
        Báº¡n lÃ  má»™t chuyÃªn gia cÃ³ kiáº¿n thá»©c vá» chá»§ Ä‘á» nÃ y.
        DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c thÃ´ng tin tham kháº£o:
        {context}
        
        CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {question}
        Tráº£ lá»i má»™t cÃ¡ch chÃ­nh xÃ¡c dá»±a trÃªn thÃ´ng tin trÃªn.
        """
    )

    # Táº¡o chuá»—i RAG
    rag_chain = RetrievalQA(
        llm=llm,
        retriever=retriever,
        return_source_documents=True,
        prompt=prompt_template
    )
    return rag_chain

# ğŸ”¹ HÃ m cháº¡y truy váº¥n RAG
def rag_query(question, collection_name="state_of_the_union"):
    rag_chain = get_rag_chain(collection_name)
    response = rag_chain({"query": question})
    
    print("\nğŸ” **Truy váº¥n:**", question)
    print("ğŸ“– **CÃ¢u tráº£ lá»i:**", response["result"])
    print("\nğŸ“‚ **Nguá»“n dá»¯ liá»‡u sá»­ dá»¥ng:**")
    for doc in response["source_documents"]:
        print(f"- {doc.metadata['source']}: {doc.page_content[:200]}...")
    
    return response

# ğŸ”¥ Test thá»­ RAG module
if __name__ == "__main__":
    question = "Ná»™i dung chÃ­nh cá»§a bÃ i diá»…n vÄƒn lÃ  gÃ¬?"
    rag_query(question)
```

---

# **ğŸ”¹ 4ï¸âƒ£ Kiá»ƒm Tra Káº¿t Quáº£**
Sau khi cháº¡y `rag.py`, báº¡n sáº½ tháº¥y káº¿t quáº£ nhÆ° sau:
```
ğŸ” **Truy váº¥n:** Ná»™i dung chÃ­nh cá»§a bÃ i diá»…n vÄƒn lÃ  gÃ¬?
ğŸ“– **CÃ¢u tráº£ lá»i:** BÃ i diá»…n vÄƒn táº­p trung vÃ o ná»n kinh táº¿, chÃ­nh sÃ¡ch quá»‘c gia vÃ  cÃ¡c káº¿ hoáº¡ch tÆ°Æ¡ng lai.

ğŸ“‚ **Nguá»“n dá»¯ liá»‡u sá»­ dá»¥ng:**
- /home/user/datasets/state_of_the_union.txt: "Ná»n kinh táº¿ Ä‘ang tÄƒng trÆ°á»Ÿng máº¡nh máº½ vÃ  chÃºng ta Ä‘Ã£ táº¡o ra hÃ ng triá»‡u viá»‡c lÃ m má»›i..."
- /home/user/datasets/state_of_the_union.txt: "ChÃºng ta Ä‘ang cam káº¿t cáº£i thiá»‡n há»‡ thá»‘ng y táº¿ vÃ  giÃ¡o dá»¥c..."
```

---

# **ğŸ”¥ Tá»•ng Káº¿t**
âœ… **HoÃ n thÃ nh bÆ°á»›c Ä‘áº§u cá»§a RAG Module!** ğŸ‰  
âœ… **Truy váº¥n ChromaDB & tÃ¬m dá»¯ liá»‡u liÃªn quan**  
âœ… **Gá»­i thÃ´ng tin vÃ o OpenAI GPT Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c**  
âœ… **Hiá»ƒn thá»‹ cáº£ cÃ¢u tráº£ lá»i & nguá»“n gá»‘c dá»¯ liá»‡u**  

ğŸš€ **Báº¡n muá»‘n má»Ÿ rá»™ng RAG vá»›i mÃ´ hÃ¬nh ná»™i bá»™ (LLaMA, Mistral) khÃ´ng?** Náº¿u khÃ´ng muá»‘n dÃ¹ng OpenAI API, mÃ¬nh cÃ³ thá»ƒ hÆ°á»›ng dáº«n cÃ¡ch cháº¡y mÃ´ hÃ¬nh cá»¥c bá»™! ğŸ”¥