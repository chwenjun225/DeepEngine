{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\"\n",
    "path_model = \"/home/chwenjun225/Projects/Foxer/models/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "path_dataset = \"/home/chwenjun225/Projects/Foxer/datasets/cot-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-04 14:24:11 __init__.py:183] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.1.8: Fast Qwen2 patching. Transformers: 4.48.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "/home/chwenjun225/Projects/Foxer/models/DeepSeek-R1-Distill-Qwen-1.5B does not have a padding token! Will use pad_token = <|vision_pad|>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True # Training với False sau \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = path_model,\n",
    "\tmax_seq_length = max_seq_length,\n",
    "\tdtype = dtype,\n",
    "\tload_in_4bit = load_in_4bit,\n",
    "\t# token = hf_token, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are an expert across multiple domains. Please apply a step-by-step Chain-of-Thought (CoT) approach to carefully analyze and solve the problem in a logical and accurate manner.\n",
    "\n",
    "Based on the given question, apply the most relevant expertise and provide a structured response.\n",
    "\n",
    "### Prompt:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<thinking>{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<thinking>Okay, so I have this question about a 61-year-old woman with some gynecological exam findings. Let me try to unpack this step by step. First, she's a 61-year-old, which suggests she's had her eyesight checked for a long time. The question is about what cystometry would reveal about her residual volume and detrusor contractions. \n",
      "\n",
      "So, the patient has a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night. That's interesting. I remember that during the night, especially when someone coughs or sneezes, there's a higher chance of leakage because the blood can drain through the nose, especially if the eyes are open. But when she's lying down or not coughing, the leakage doesn't happen. \n",
      "\n",
      "Now, she's undergoing a gynecological exam and a Q-tip test. Let me think about what that entails. The Q-tip test is used to assess the presence of detrusor contractions. Detrusor contractions are a type of contractions that cause gas, especially in women. They are usually associated with coughing or sneezing and can cause a drop in gas volume, which is what cystometry is used to detect.\n",
      "\n",
      "So, during the Q-tip test, if there are contractions, the gas volume should drop. The Q-tip itself is a small needle that's inserted into the vagina and passed through the cervium. When contractions occur, the gas in the cavity drops, and the Q-tip can detect that change. \n",
      "\n",
      "In this case, the patient didn't have leakage at night, which suggests that the detrusor contractions were not causing gas because the leakage would have been more prominent at night. But during the day, she had involuntary urine loss, which probably indicates gas. \n",
      "\n",
      "Wait, but the question is about what cystometry would reveal. So, if she has contractions, cystometry would show a decrease in residual volume. That's because during contractions, gas is released, reducing the volume you feel. \n",
      "\n",
      "But if she didn't have contractions, cystometry wouldn't show a decrease. Since the patient had contractions (because she had leakage during the day but not at night), cystometry would show a decrease in residual volume.\n",
      "\n",
      "Additionally, detrusor contractions cause a drop in gas, which would be detected by the Q-tip test. But since she had contractions, the cystometry would show a decrease in residual volume.\n",
      "\n",
      "So, putting it all together, the cystometry would reveal a decrease in residual volume because of detrusor contractions.\n",
      "</think>\n",
      "\n",
      "Cystometry would reveal a decrease in residual volume due to detrusor contractions. \n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Patient Profile:** A 61-year-old woman with involuntary urine loss during activities (like coughing or sneezing) but no leakage at night.\n",
      "\n",
      "2. **Test Conducted:** Gynecological exam and Q-tip test to assess detrusor contractions and residual volume.\n",
      "\n",
      "3. **Q-tip Test Implications:** \n",
      "   - Detects detrusor contractions (gas causing volume drop).\n",
      "   - No contractions if there's no leakage at night.\n",
      "\n",
      "4. **Cystometry Implications:**\n",
      "   - Presence of contractions (detrusor) → Decrease in residual volume.\n",
      "   - No contractions → No decrease.\n",
      "\n",
      "5. **Conclusion:** Cystometry would show a decrease in residual volume due to contractions.\n",
      "\n",
      "**Answer:** Cystometry would reveal a decrease in residual volume due to detrusor contractions.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer([prompt_style.format(prompt, \"\")], return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "\tinput_ids=inputs.input_ids,\n",
    "\tattention_mask=inputs.attention_mask,\n",
    "\tmax_new_tokens=1200,\n",
    "\tuse_cache=True,\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are an expert across multiple domains. Please apply a step-by-step Chain-of-Thought (CoT) approach to carefully analyze and solve the problem in a logical and accurate manner.\n",
    "\n",
    "Based on the given question, apply the most relevant expertise and provide a structured response.\n",
    "\n",
    "### Prompt:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task, paired with an input that provides further context.\\nWrite a response that appropriately completes the request.\\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are an expert across multiple domains. Please apply a step-by-step Chain-of-Thought (CoT) approach to carefully analyze and solve the problem in a logical and accurate manner.\\n\\nBased on the given question, apply the most relevant expertise and provide a structured response.\\n\\n### Prompt:\\nExplain the difference between truth and justification in epistemology. How can these concepts lead to different combinations of true/false beliefs and justified/unjustified beliefs? Provide examples for each possible combination.\\n\\n### Response:\\n<thinking>\\n<initial_analysis>\\nTask: Explain the difference between truth and justification in epistemology and provide examples of different belief combinations\\nApproach: Break down concepts, analyze relationships, and provide examples\\nComplexity: Moderate to High\\n</initial_analysis>\\n\\n<conscious_thought>\\nI need to clearly distinguish between truth and justification, explain their relationship, and then systematically cover all possible combinations of true/false and justified/unjustified beliefs with examples.\\n</conscious_thought>\\n\\n<step_by_step>\\n1. Define truth:\\n   - Corresponds to reality\\n   - Binary (true or false)\\n   - Absolute (not relative to persons, times, places, or cultures)\\n\\n2. Define justification:\\n   - Epistemic justification: having good reasons to believe something\\n   - Can vary in degree\\n   - Relative to persons\\n\\n3. Analyze relationship between truth and justification:\\n   - Truth is about the correspondence of a proposition to reality\\n   - Justification is about the reasons a person has for believing a proposition\\n   - They are independent: a belief can be true or false, justified or unjustified\\n\\n4. List possible combinations:\\n   a) True and justified belief\\n   b) True and unjustified belief\\n   c) False and justified belief\\n   d) False and unjustified belief\\n\\n5. Generate examples for each combination\\n</step_by_step>\\n\\n<reflection>\\nI've covered the key concepts and their relationships. Now, I need to ensure my examples are clear and diverse to illustrate each combination effectively.\\n</reflection>\\n\\n<feeling>\\nConfidence: High\\nEmotional response: Engaged and focused\\n</feeling>\\n</thinking>\\n\\n<output>\\nTruth and justification are two distinct concepts in epistemology that often get conflated. Truth refers to whether a proposition corresponds to reality, and in classical logic, it's binary (either true or false) and absolute (not relative to individuals or contexts). Justification, on the other hand, relates to whether a person has good reasons for believing something. It can vary in degree and is relative to individuals.\\n\\nThese concepts can lead to four different combinations of beliefs:\\n\\n1. True and justified belief:\\nExample: A meteorologist believes it will rain tomorrow based on comprehensive weather data. It does indeed rain the next day.\\n\\n2. True but unjustified belief:\\nExample: Someone guesses that there are 525 jelly beans in a jar without counting. By sheer luck, they happen to be correct.\\n\\n3. False but justified belief:\\nExample: A jury convicts a defendant based on seemingly conclusive evidence, but unknown to them, the defendant is actually innocent.\\n\\n4. False and unjustified belief:\\nExample: A person believes the Earth is flat based on conspiracy theories they read online, despite overwhelming scientific evidence to the contrary.\\n\\nThese examples demonstrate that the truth of a proposition is independent of whether someone is justified in believing it. This understanding is crucial in epistemology and highlights the complexity of knowledge acquisition and belief formation.\\n<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "\tprompts = examples[\"prompt\"]\n",
    "\tresponses = examples[\"response\"]\n",
    "\ttexts = []\n",
    "\tfor prompt, response in zip(prompts, responses):\n",
    "\t\ttext = train_prompt_style.format(prompt, response) + EOS_TOKEN\n",
    "\t\ttexts.append(text)\n",
    "\treturn {\"texts\": texts}\n",
    "\n",
    "dataset = load_dataset(path_dataset, split=\"train[0:6000]\", trust_remote_code=True)\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "dataset['texts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.1.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "\tmodel,\n",
    "\tr=16,  \n",
    "\ttarget_modules=[\n",
    "\t\t\"q_proj\",\n",
    "\t\t\"k_proj\",\n",
    "\t\t\"v_proj\",\n",
    "\t\t\"o_proj\",\n",
    "\t\t\"gate_proj\",\n",
    "\t\t\"up_proj\",\n",
    "\t\t\"down_proj\",\n",
    "\t],\n",
    "\tlora_alpha=16,\n",
    "\tlora_dropout=0,  \n",
    "\tbias=\"none\",  \n",
    "\tuse_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "\trandom_state=3407,\n",
    "\tuse_rslora=False,  \n",
    "\tloftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0c975b917d4d779d0bd3f70f5269f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "\tmodel=model,\n",
    "\ttokenizer=tokenizer,\n",
    "\ttrain_dataset=dataset,\n",
    "\tdataset_text_field=\"texts\",\n",
    "\tmax_seq_length=max_seq_length,\n",
    "\tdataset_num_proc=2,\n",
    "    packing=False, # Can make training 5x faster for short sequences.\n",
    "\targs=TrainingArguments(\n",
    "\t\tper_device_train_batch_size=2,\n",
    "\t\tgradient_accumulation_steps=4,\n",
    "\t\t# Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
    "\t\twarmup_steps=5,\n",
    "        max_grad_norm=0.3,\n",
    "\t\tmax_steps=60,\n",
    "\t\tlearning_rate=2e-4,\n",
    "\t\tfp16=not is_bfloat16_supported(),\n",
    "\t\tbf16=is_bfloat16_supported(),\n",
    "\t\tlogging_steps=10,\n",
    "\t\toptim=\"adamw_8bit\",\n",
    "\t\tweight_decay=0.01,\n",
    "\t\tlr_scheduler_type=\"linear\",\n",
    "\t\tseed=3407,\n",
    "\t\toutput_dir=\"./results\",\n",
    "        report_to=\"tensorboard\",\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 6,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 18,464,768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.559100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.113700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nếu tiếp tục train sử dụng --> trainer_stats = trainer.train(\"checkpoint-9500\") \n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<thinking> <conscious_thought>\n",
      "<initial_analysis>\n",
      "Task: Identify the most likely outcome of a cystometry test based on gynecological exam and Q-tip results\n",
      "Approach: Analyze the findings from gynecological exam and cystometry test\n",
      "Complexity: Medium\n",
      "</conscious_thought>\n",
      "<conscious_thought>\n",
      "Key points:\n",
      "- Long history of involuntary urine loss\n",
      "- No leakage at night\n",
      "- Results from gynecological exam and Q-tip test\n",
      "</conscious_thought>\n",
      "<step_by_step>\n",
      "1. Analyze gynecological exam results:\n",
      "   - No leakage at night suggests normal intrauterine spaces\n",
      "   - Urinary retention during activities (coughing, sneezing) is unusual\n",
      "2. Consider Q-tip test results:\n",
      "   - No contractions indicate no detrusor contractions\n",
      "3. Apply cystometry results:\n",
      "   - No contractions likely indicate no residual volume\n",
      "   - No contractions suggest no detrusor contractions\n",
      "</step_by_step>\n",
      "<reflection>\n",
      "This analysis aligns with the initial findings from the gynecological exam and Q-tip test. The results from the cystometry test suggest a normal intrauterine space and no contractions, indicating no residual volume or detrusor contractions.\n",
      "</reflection>\n",
      "<conscious_thought>\n",
      "Implications:\n",
      "Residual volume may be normal or slightly reduced, but based on the findings, there's no contractions to suggest a significant reduction\n",
      "</conscious_thought>\n",
      "<feeling>\n",
      "Confidence: High\n",
      "Emotional response: Confident in the analysis and understanding of the findings\n",
      "</feeling>\n",
      "<self_improvement>\n",
      "To improve my analysis, I should consider:\n",
      "- Possible causes for residual volume changes\n",
      "- Impact of contractions on cystometry results\n",
      "</self_improvement>\n",
      "</thinking>\n",
      "\n",
      "<output>\n",
      "Based on the gynecological exam and Q-tip test results, the most likely outcome of this cystometry test would be:\n",
      "- No contractions (detrusor contractions)\n",
      "- Normal intrauterine spaces\n",
      "This suggests that there may be no residual volume in the ureter or bladder. However, it's important to note that residual volume can change based on activity and may not always be the case in all patients. The findings from the gynecological exam and Q-tip test support the idea of normal intrauterine spaces and no contractions, indicating a normal ureteric space.\n",
      "</output>\n",
      "<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "\tinput_ids=inputs.input_ids,\n",
    "\tattention_mask=inputs.attention_mask,\n",
    "\tmax_new_tokens=1200,\n",
    "\tuse_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 15.51 out of 31.25 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 100.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "new_model_local = \"finetuned_DeepSeek-R1-Distill-Qwen-1.5B_finetune_CoT_ReAct\"\n",
    "model.save_pretrained(new_model_local) \n",
    "tokenizer.save_pretrained(new_model_local)\n",
    "\n",
    "model.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval --model hf \\\n",
    "--model_args pretrained=\"/home/chwenjun225/Projects/Foxer/notebooks/DeepSeek-R1-Distill-Qwen-1.5B_finetune_CoT_ReAct/finetuned_DeepSeek-R1-Distill-Qwen-1.5B_finetune_CoT_ReAct\" \\\n",
    "--tasks lambada_openai,hellaswag,piqa,arc_easy,arc_challenge,winogrande,openbookqa \\\n",
    "--device cuda \\\n",
    "--batch_size auto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foxer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
