import re
import json
import fire 
import logging
import streamlit as st 



from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage



from langgraph.graph import StateGraph, START, END



from langserve import add_routes



from state import State, default_messages
from const_vars import QUERIES, DEBUG, CONFIG, CHECKPOINTER, STORE, CHAT_HISTORY_VECTORSTORE
from nodes import manager_agent, request_verify, prompt_agent, retrieval_augmented_planning_agent, data_agent, model_agent
from AutoChainOfThought.api import chain_of_thought



# TODO: T√≠ch h·ª£p auto-cot.

# TODO: T·ªëi ∆∞u prompt.

# TODO: Build RAG pipeline.

# TODO:  `*state["messages"],` t·ª± ƒë·ªông ƒë∆∞a ng·ªØ c·∫£nh l·ªãch s·ª≠ tr√≤ chuy·ªán v√†o m√¥ h√¨nh b·∫±ng c√°ch pass t·ª´ng th√†nh ph·∫ßn list v√†o.

# TODO: √ù t∆∞·ªüng s·ª≠ d·ª•ng Multi-Agent g·ªçi ƒë·∫øn Yolov8 API, Yolov8 
# API s·∫Ω l·∫•y m·ªçi h√¨nh ·∫£nh c·ª° nh·ªè n√≥ ph√°t hi·ªán  ƒë∆∞·ª£c l√† l·ªói v√† 
# ƒë∆∞a v√†o m√¥ h√¨nh llama3.2-11b-vision ƒë·ªÉ ƒë·ªçc ·∫£nh, sau ƒë√≥ 
# Llama3.2-11b-vision g·ª≠i l·∫°i text ƒë·∫øn Multi-Agent ƒë·ªÉ 
# Multi-Agent x√°c ƒë·ªãnh xem ƒë·∫•y c√≥ ph·∫£i l√† l·ªói kh√¥ng.

# N·∫øu mu·ªën v·∫≠y th√¨ hi·ªán t·∫°i ta c·∫ßn c√≥ data-agent v√† model-agent
# data-agent ƒë·ªÉ generate d·ªØ li·ªáu training, model-agent ƒë·ªÉ vi·∫øt 
# ki·∫øn tr√∫c model vision.

# B√¢y gi·ªù c·∫ßn build tools tr∆∞·ªõc cho m√¥ h√¨nh, bao g·ªìm 
# tool vision, tool genData, tool llama3.2-11b-vision-instruct

# Nh∆∞ng t·∫°i sao l·∫°i ko d√πng vision yolov8 ƒë·ªÉ finetune. M·ª•c ti√™u 
# ·ªü ƒë√¢y, ta s·∫Ω t·∫≠n d·ª•ng c·∫£ s·ª©c m·∫°nh c·ªßa LLM-Vision, ƒë·ªÉ hi·ªÉu r√µ
# h√¨nh ·∫£nh c√≥ g√¨, sau ƒë√≥ g·ª≠i v·ªÅ cho LLM-instruct ƒë·ªÉ x·ª≠ l√Ω text 
# t·ª´ LLM-vision.

# **1. Image-to-Image Generation (CycleGAN, Pix2Pix, StyleGAN)**
# **2. Data Augmentation (Bi·∫øn ƒë·ªïi d·ªØ li·ªáu)**

# TODO: L·∫•y tr·∫°ng th√°i, l·ªãch s·ª≠ b·∫±ng c√°ch `app.get_state(CONFIG).values`

# TODO: Working on this, build integrate auto chain of thought to multi-agent
# x = cot(method="auto_cot", question="", debug=False)

# logging.basicConfig(level=logging.CRITICAL)



workflow = StateGraph(State)

workflow.add_node("MANAGER_AGENT", manager_agent)
workflow.add_node("REQUEST_VERIFY", request_verify)
workflow.add_node("PROMPT_AGENT", prompt_agent)
workflow.add_node("RAP", retrieval_augmented_planning_agent)
workflow.add_node("DATA_AGENT", data_agent)
workflow.add_node("MODEL_AGENT", model_agent)

workflow.add_edge(START, "MANAGER_AGENT")
workflow.add_edge("MANAGER_AGENT", "REQUEST_VERIFY")
workflow.add_conditional_edges("REQUEST_VERIFY", request_verify, ["PROMPT_AGENT", END])
workflow.add_edge("PROMPT_AGENT", END)

app = workflow.compile(
	store=STORE, 
	debug=DEBUG, 
	checkpointer=CHECKPOINTER, 
	name="foxconn_fulian_b09_ai_research_tranvantuan_v1047876")



def main() -> None:
	"""X·ª≠ l√Ω truy v·∫•n c·ªßa ng∆∞·ªùi d√πng v√† hi·ªÉn th·ªã ph·∫£n h·ªìi t·ª´ AI."""
	for i, user_query in enumerate(QUERIES, 1):
		print(f"\nüë®_query_{i}:")
		print(user_query)
		print("\nü§ñ_response:")
		user_query = user_query.strip()
		if user_query.lower() == "exit": break
		state_data = app.invoke(input={"human_query": [
				HumanMessage(user_query)], "messages": default_messages()
			}, config=CONFIG
		)
		if not isinstance(state_data, dict): 
			raise ValueError("[ERROR]: app.invoke() kh√¥ng tr·∫£ v·ªÅ dictionary.")
		if "messages" not in state_data: 
			raise ValueError("[ERROR]: Key 'messages' kh√¥ng c√≥ trong k·∫øt qu·∫£.")
		messages = state_data["messages"]
		print("\n===== [CONVERSATION RESULTS] =====\n")
		display_conversation_results(messages)
		print("\n===== [END OF CONVERSATION] =====\n")
		


def display_conversation_results(messages: dict) -> None:
	"""Hi·ªÉn th·ªã k·∫øt qu·∫£ h·ªôi tho·∫°i t·ª´ t·∫•t c·∫£ c√°c agent trong h·ªá th·ªëng."""
	if not messages:
		print("[INFO]: Kh√¥ng c√≥ tin nh·∫Øn n√†o trong h·ªôi tho·∫°i.")
		return
	for node, msgs in messages.items():
		print(f"\n[{node}]")
		if isinstance(msgs, dict):
			for msg_category, msg_list in msgs.items():
				if msg_list:
					print(f"  {msg_category}:")
					for msg in msg_list:
						content = getattr(msg, "content", "[No content]")
						print(f"\t- {content}")
		else:
			raise ValueError(f"`msgs` ph·∫£i l√† m·ªôt dictionary ch·ª©a danh s√°ch tin nh·∫Øn, `msgs` hi·ªán t·∫°i l√†: {msgs}")



if __name__ == "__main__":
	fire.Fire(main)
