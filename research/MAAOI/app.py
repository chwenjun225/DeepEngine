import json
import asyncio
import cv2 
import fire 
import numpy as np 
import gradio as gr 
from PIL import Image 



from langchain_core.messages import BaseMessage, AIMessage



from ultralytics.engine.results import Results



from agentic import AGENTIC
from const import (
	CONFIG						,
	PRODUCT_STATUS				,
	STATUS_LOCK					,

	YOLO_OBJECT_DETECTION		,
	VISION_LLM			,
)
from utils import (
	image_to_base64				,
	expand_bbox					,
	get_latest_msg				,
)



def get_status_product() -> str:
	"""Tráº£ vá» tráº¡ng thÃ¡i lá»—i hiá»‡n táº¡i cá»§a sáº£n pháº©m."""
	with STATUS_LOCK:
		return PRODUCT_STATUS



async def async_llm_inference(prompt):
	"""Thá»±c thi LLM khÃ´ng cháº·n."""
	return await asyncio.to_thread(
		VISION_LLM.invoke, prompt
	)



def single_frame_detections_to_json(results:Results, frame_id:int) -> str:
	"""Chuyá»ƒn káº¿t quáº£ YOLOv8 tá»« 1 frame thÃ nh JSON, tá»‘i Æ°u tá»‘c Ä‘á»™."""
	result = results[0]
	boxes: np.ndarray = result.boxes.xyxy.cpu().numpy().astype(int)
	confidences: np.ndarray = result.boxes.conf.cpu().numpy().astype(float)
	class_ids: np.ndarray = result.boxes.cls.cpu().numpy().astype(int)
	class_names = result.names
	frame_data = {
		"id": frame_id, 
		"metadata": [
			{
				"bbox": {"x1": int(x1), "y1": int(y1), "x2": int(x2), "y2": int(y2)},
				"confidence": round(float(conf), 3),
				"class_id": int(cls_id), 
				"label": class_names[int(cls_id)]
			}
			for (x1, y1, x2, y2), conf, cls_id in zip(boxes, confidences, class_ids)
		]
	}
	return frame_data



async def async_process_frames(ctx_frames:list[Image.Image]) -> tuple[Image.Image, list[str]]: 
	"""Xá»­ lÃ½ khung hÃ¬nh báº±ng YOLO vÃ  LLM vá»›i asyncio."""
	ctx_frames_metadata = [] ### Khá»Ÿi táº¡o context-frames-metadata
	for idx, frame in enumerate(ctx_frames):
		results = YOLO_OBJECT_DETECTION.predict(frame, conf=0., iou=0.1, max_det=5) 
		frame_metadata = single_frame_detections_to_json(results, idx) 
		ctx_frames_metadata.append(frame_metadata)
	#################################### TODO: Tiáº¿p theo hÃ£y viáº¿t logic xá»­ lÃ½ cho cÃ¡c agent trong file nodes
	#################################### BÄ‚T Äáº¦U VIáº¾T á»ž ÄÃ‚Y ################################################
	response = AGENTIC.invoke(
		input={"VISION_AGENT_MSGS": [AIMessage(
			content=ctx_frames_metadata, name="VISION_AGENT"
		)]}, 
		config=CONFIG
	)

	processed_img, ngok, reason = ["áº¢nh pil Ä‘Ã£ váº½ cÃ¡c dáº¥u hiá»‡u lá»—i","PRODUCT_STATUS OK hoáº·c NG",  "LÃ½ luáº­n Ä‘á»ƒ hiá»ƒn thá»‹"] ### Giáº£ láº­p káº¿t quáº£ Ä‘áº§u ra 


	# TODO: NgÃ y mai cáº§n build nhanh má»™t há»‡ thá»‘ng Multi-Agent á»Ÿ Ä‘Ã¢y Ä‘á»ƒ lÃ½ giáº£i tÃ­nh toÃ¡n cÃ¡c "ctx_frame_metadata"
	print("ctx_frames_metadata:", ctx_frames_metadata) 
	print("DEBUG")

	### IMPORTANT: Káº¿t quáº£ Ä‘áº§u ra pháº£i lÃ  má»™t list["áº¢nh pil Ä‘Ã£ váº½ cÃ¡c dáº¥u hiá»‡u lá»—i","PRODUCT_STATUS OK hoáº·c NG",  "LÃ½ luáº­n Ä‘á»ƒ hiá»ƒn thá»‹"]

	### ÄÃ£ cÃ³ multi_frame_ctx_metadata, giá» lÃ m gÃ¬ tiáº¿p
	### 1. cho vÃ o agent.invoke 
		### Sá»­a láº¡i Ä‘Æ°á»ng dáº«n model file --> Ä‘Ã£ sá»­a xong
		### Viáº¿t agent.invoke
		### NhÆ°ng giá» lÃ m tháº¿ nÃ o Ä‘á»ƒ cho agent workflow tÆ°Æ¡ng tÃ¡c hay nÃ³i cÃ¡ch khÃ¡c lÃ  bÃ³c tÃ¡ch cÃ¡c thÃ´ng tin tá»« frame nhá»‰
		### cÃ³ hai hÆ°á»›ng
		### 1. Giáº£i quyáº¿t tá»« cÃ¡ch nhÃ¬n nháº­n con ngÆ°á»i
			### Suy luáº­n nhanh: khi nháº­n má»™t chuá»—i thÃ´ng tin nhÆ° nÃ y ta sáº½ nhÃ¬n vÃ o pattern vÃ  nhÃ¬n vÃ o confidence Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cÃ³ thá»ƒ lÃ  sá»­ dá»¥ng tÃ­nh trung bÃ¬nh cá»™ng
				### NhÆ°ng khÃ´ng thá»ƒ tÃ­nh theo kiá»ƒu trung bÃ¬nh cá»™ng Ä‘Æ°á»£c 
		### 2. Giáº£i quyáº¿t tá»« cÃ¡ch nhÃ¬n nháº­n AI
			### Suy luáº­n nhanh: lÃ m tháº¿ nÃ o má»™t há»‡ thá»‘ng AI cÃ³ thá»ƒ xá»­ lÃ½ Ä‘Æ°á»£c khi nháº­n Ä‘Æ°á»£c task vÃ  docs
			### PhÃ¢n tÃ­ch: Task ---  Ä‘Æ°a ra káº¿t luáº­n OK hay NG Ä‘á»‘i vá»›i báº£n máº¡ch PCB 
			### Dá»¯ kiá»‡n: 10 frames áº£nh, cÃ³ chá»©a vá»‹ trÃ­ xyxy, confidence, class_id, label 
				### lÃ m tháº¿ nÃ o nhá»‰?
				### Cáº§n cÃ³ má»™t quÃ¡ trÃ¬nh suy luáº­n tá»«ng bÆ°á»›c 
				### 1. Lá»—i á»Ÿ Ä‘Ã¢y lÃ  gÃ¬, Ä‘Ã¢u lÃ  lá»—i phá»• biáº¿n? CÃ³ xu hÆ°á»›ng gÃ¬ trong thá»i gian 
				### 2. ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng 
				### 	--- trong 10 frames, cÃ¡c confidence cao mÃ  xuáº¥t hiá»‡n nhiá»u --> lá»—i tháº­t 
				### 	--- cÃ²n náº¿u confidence tháº¥p mÃ  xuáº¥t hiá»‡n Ã­t thÃ¬ lÃ  lá»—i áº£o
				### CÃ³ má»™t hÆ°á»›ng sau cÃ³ thá»ƒ sá»­ dá»¥ng 



				### 1. VISION AGENT
				### 	--- ÄÃ£ hoÃ n thÃ nh



				### 2. TEMPORAL PATTERN AGENT 
				###		--- Group láº¡i cÃ¡c lá»—i kiá»ƒu nhÆ° ```
				### frame id 1: lá»—i missing hole xuáº¥t hiá»‡n 6 láº§n táº¡i cÃ¡c vá»‹ trÃ­ cÃ¹ng vá»›i cÃ¡c Ä‘á»™ tin cáº­y nhÆ° sau 
				### Ä‘á»™ tin cáº­y 89%, lá»—i xuáº¥t hiá»‡n táº¡i vá»‹ trÃ­ xyxy
				### Ä‘á»™ tin cáº­y 15%, lá»—i xuáº¥t hiá»‡n táº¡i vá»‹ trÃ­ xyxy
				### Ä‘á»™ tin cáº­y 12%, lá»—i xuáº¥t hiá»‡n táº¡i vá»‹ trÃ­ xyxy
				### ...```



				### 3. Defect Reasoning Agent 
				### 	--- láº¥y thÃ´ng tin tá»« TEMPORAL_PATTERN_AGENT Ä‘á»ƒ suy luáº­n 
				### 	Giáº£ láº­p Agent suy luáº­n: 
				### ðŸ¤¯ CÃ³ thá»ƒ dÃ¹ng LLM Ä‘á»ƒ há»i kiá»ƒu:
				### 	--- "Liá»‡u cÃ¡c lá»—i nÃ y liÃªn quan Ä‘áº¿n má»™t nguyÃªn nhÃ¢n gá»‘c?"
				###		--- "ÄÃ¢u lÃ  lá»—i phá»• biáº¿n? CÃ³ xu hÆ°á»›ng gÃ¬ trong thá»i gian?"



				### 4. Criticality Assessment Agent
				### ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng:
				###		--- VÃ­ dá»¥ Confidence tháº¥p --- cÃ³ thá»ƒ ignore
				### 	--- Náº¿u má»™t lá»—i tá»“n táº¡i qua nhiá»u frame ---> Lá»—i tháº­t 
				### Gá»£i Ã½ prompt: Dá»±a trÃªn metadata, Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a tá»«ng lá»—i [...metadata...]



				### 5. Report Generator Agent
				### 	Táº¡o bÃ¡o cÃ¡o ngÆ°á»i dÃ¹ng:
				### 	VÄƒn báº£n tá»± nhiÃªn mÃ´ táº£: "CÃ³ 3 lá»—i missing_hole phÃ¡t hiá»‡n liÃªn tá»¥c tá»« frame 2â€“8. Lá»—i short cÃ³ xuáº¥t hiá»‡n nhÆ°ng confidence tháº¥p."
				### 	Gá»£i Ã½:
				### 	Tráº£ vá» text, summary, markdown, hoáº·c JSON structured report.



				### 6. Bonus Agent: Visual Agent
				###		Ghi Ä‘Ã¨ label lÃªn áº£nh báº±ng mÃ u khÃ¡c nhau theo severity.
				###		CÃ³ thá»ƒ crop áº£nh lá»—i Ä‘á»ƒ Ä‘Æ°a vÃ o bÃ¡o cÃ¡o cuá»‘i.


				### HÆ°á»›ng liÃªn káº¿t agent vá»›i LangGraph:
				###			start â†’ Vision Agent
				###		        â†“
				###		    Temporal Agent
				###		        â†“
				###		    Reasoning Agent
				###		        â†“
				###		  [Branch]
				###		   â†™      â†˜
				###	Crit.Agent  Visual Agent
				###		       â†“         â†“
				###	 â†’ Report Generator â†’ END



	# 1. ÄÃ£ viáº¿t xong sÆ¡ bá»™ prompts 
	# 2. Báº¯t Ä‘áº§u ká»ƒ tá»« hÃ´m nay táº¥t cáº£ cÃ¡c thÃ nh pháº§n trong chÆ°Æ¡ng trÃ¬nh cáº§n pháº£i tráº£ vá» State --- LangGraph 
	# Báº¯t Ä‘áº§u viáº¿t chÆ°Æ¡ng trÃ¬nh langgraph, nhÆ°ng cÃ³ thÃªm váº¥n Ä‘á» ná»¯a
	# náº¿u Ä‘Ã¢y lÃ  má»™t quÃ¡ trÃ¬nh suy luáº­n tuáº§n tá»± thÃ¬ nÃªn thiáº¿t káº¿ State nhÆ° tháº¿ nÃ o 

	# Hiá»‡n táº¡i cáº§n thiáº¿t káº¿ State

	# State lÃ  máº¡ch mÃ¡u lÆ°u thÃ´ng giá»¯a cÃ¡c agent

	# ÄÃ¢y lÃ  má»™t state tuáº§n tá»±, vÃ¬ váº­y cÃ³ thá»ƒ sá»­ dá»¥ng kiá»ƒu nhÆ° list[BaseMessage]

	# agent sau cÃ³ thá»ƒ láº¥y thÃ´ng tin tá»« agent trÆ°á»›c báº±ng cÃ¡ch sá»­ dá»¥ng state["messages"][-1]


















	### ÄÃ¢y lÃ  hÃ¬nh áº£nh plot káº¿t quáº£ lÃªn yolo, bÃ¢y giá» chÆ°a cáº§n thiáº¿t
	processed_img = Image.fromarray(results[0].plot()[..., ::-1]) 
	bboxes = [list(map(int, box.xyxy[0])) for box in results[0].boxes] 
	tasks = []
	for bbox in bboxes: 
		bbox_expanded = expand_bbox(bbox)
		cropped = image.crop(bbox_expanded) 
		b64_img = image_to_base64(cropped) 
		prompt = VISUAL_AGENT_PROMPT_MSG.format(base64_image=b64_img)
		tasks.append(async_llm_inference(prompt))
	texts = await asyncio.gather(*tasks)
	return processed_img, texts



async def async_video_processing(video_path:str, resize_to:tuple=(640, 640), ctx_frames_limit:int=10) -> any:	
	"""Xá»­ lÃ½ video khÃ´ng cháº·n báº±ng asyncio."""
	cap = cv2.VideoCapture(video_path)
	if not cap.isOpened():
		yield None, "Cannot open video", ""
		return

	ctx_frames = []
	while cap.isOpened():
		ret, frame = cap.read()
		if not ret: 
			break

		frame = Image.fromarray(frame[..., ::-1]).resize(resize_to) 
		ctx_frames.append(frame) 

		if len(ctx_frames) == ctx_frames_limit: ### Náº¿u tÃ­ch Ä‘á»§ 10 frames thÃ¬ xá»­ lÃ½ 
			processed_img, texts = await async_process_frames(ctx_frames) ### Xá»­ lÃ½ asyncio vá»›i Multi-Agent System
			text_combined = " | ".join([
				text.content 
					if isinstance(text, BaseMessage) 
					else str(text) 
					for text in texts
			]) ### Chuyá»ƒn káº¿t quáº£ reasoning ra giao diá»‡n 
			yield processed_img, "NG", text_combined ### Stream káº¿t quáº£ ra giao diá»‡n 
			ctx_frames.clear() ### LÃ m sáº¡ch context-frames 
	cap.release()
	yield None, "Video ended", ""



def __detect_pcb_video(video_path: str) -> any:
	"""Giao diá»‡n Gradio Ä‘á»ƒ xá»­ lÃ½ video."""
	try:
		loop = asyncio.get_running_loop()
	except RuntimeError:
		loop = asyncio.new_event_loop()
		asyncio.set_event_loop(loop)
	async def async_generator_wrapper():
		async for processed_img, status, text_combined in async_video_processing(video_path):
			yield processed_img, status, text_combined
	async_gen = async_generator_wrapper()
	while True:
		try:
			result = loop.run_until_complete(async_gen.__anext__())
			yield result
		except StopAsyncIteration:
			break



async def __detect_pcb_image(image: Image.Image) -> any:
	"""Xá»­ lÃ½ áº£nh PCB báº±ng YOLO vÃ  LLM."""
	try:
		processed_img, texts = await async_process_frames(image)
		text_combined = " | ".join([
			text.content \
				if isinstance(text, BaseMessage) \
				else str(text) \
				for text in texts
		])
		status = get_status_product()
		return processed_img, status, text_combined
	except Exception as e:
		return None, "Error during image processing", str(e)



def __chatbot(user_query: str, history: list[dict]) -> list[dict]:
	"""Handle user input and return assistant reply in OpenAI-style format."""
	if not user_query.strip():
		return history + [{"role": "assistant", "content": "You haven't entered a message."}]
	state_data = AGENTIC.invoke(
		input={"messages": [{"role": "user", "content": user_query}]}, 
		config=CONFIG
	)
	ai_msg = get_latest_msg(state=state_data)
	history.extend([
		{"role": "user", "content": user_query},
		{"role": "assistant", "content": ai_msg.content}
	])
	return history



def main() -> None:
	"""Giao diá»‡n á»©ng dá»¥ng."""
	with gr.Blocks() as ui:
		gr.Markdown("# AI-Research --- AutoML-MultiAgent for AOI Tasks --- Owner: é™³æ–‡ä¿Š --- V1047876")
		with gr.Row():
			### Reasoning Agent
			with gr.Column():
				gr.Markdown("### Reasoning Agent")
				chatbot = gr.Chatbot(
					label="Reasoning Agent", 
					height=400, 
					type="messages"
				)
				chatbot_input = gr.Textbox(
					label="Type a messages...", 
					placeholder="Ask me anything..."
				)
				chatbot_button = gr.Button("Submit")
				chatbot_button.click(
					fn=__chatbot, 
					inputs=[chatbot_input, chatbot], 
					outputs=chatbot
				)
			### Vision Agent
			with gr.Column():
				gr.Markdown("### Vision Agent")
				### Image predict
				with gr.Tab("Image Predict"):
					image_input = gr.Image(label="Upload Image", type="pil", height=160)
					image_output = gr.Image(label="Processed Image")
					status_box_img = gr.Textbox(label="Product Status", interactive=False)
					reasoning_output_img = gr.Textbox(label="Reasoning", lines=6)
					gr.Button("Analyze Image").click(
						fn=__detect_pcb_image, 
						inputs=image_input,
						outputs=[image_output, status_box_img, reasoning_output_img]
					)
				### Video predict
				with gr.Tab("Video Predict"):
					video_input = gr.File(label="Upload Video", file_types=[".mp4", ".avi"], height=120)
					video_output = gr.Image(label="Predicted Frame", streaming=True) 
					status_box = gr.Textbox(label="Product Status", value=PRODUCT_STATUS, interactive=False)
					reasoning_output = gr.Textbox(label="LLaMA3.2 Reasoning Result", lines=8)
					process_video_button = gr.Button("Start Video Inspection")
					process_video_button.click(
						fn=__detect_pcb_video, 
						inputs=video_input,
						outputs=[video_output, status_box, reasoning_output]
					)
	ui.launch()



if __name__ == "__main__":
	fire.Fire(main)
