{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "import random\n",
    "import tqdm\n",
    "import requests\n",
    "import json\n",
    "import json5\n",
    "import fire \n",
    "import streamlit as st \n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError, TypeAdapter\n",
    "from typing_extensions import (Annotated, TypedDict, Sequence, Union, Optional, Literal, List, Dict, Iterator, Any, Type)\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.tools import InjectedToolCallId, BaseTool\n",
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import (HumanMessage, AIMessage, SystemMessage, BaseMessage, ToolMessage)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.managed import IsLastStep\n",
    "from langgraph.graph import (MessagesState, StateGraph, START, END)\n",
    "from langgraph.prebuilt import (create_react_agent, ToolNode, tools_condition)\n",
    "\n",
    "\n",
    "\n",
    "from tools import (add, subtract, multiply, divide, power, square_root)\n",
    "from prompts import Prompts \n",
    "\n",
    "\n",
    "\n",
    "NAME = \"FOXCONN-AI Research\"\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "\n",
    "BEGIN_OF_TEXT\t\t=\t\"<|begin_of_text|>\"\n",
    "END_OF_TEXT\t\t\t= \t\"<|end_of_text|>\"\n",
    "START_HEADER_ID\t\t= \t\"<|start_header_id|>\"\n",
    "END_HEADER_ID\t\t= \t\"<|end_header_id|>\"\n",
    "END_OF_MESSAGE_ID\t= \t\"<|eom_id|>\"\n",
    "END_OF_TURN_ID\t\t= \t\"<|eot_id|>\"\n",
    "\n",
    "\n",
    "\n",
    "MSG_TYPES = {\tSystemMessage: \"SYS\", HumanMessage: \"HUMAN\", AIMessage: \"AI\"\t}\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_AGENTS: Dict[str, Dict[str, List[BaseMessage]]] = {\n",
    "\t\"MANAGER_AGENT\": \t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "\t\"REQUEST_VERIFY\": \t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "\t\"PROMPT_AGENT\": \t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "\t\"DATA_AGENT\": \t\t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "\t\"MODEL_AGENT\": \t\t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "\t\"OP_AGENT\": \t\t{\t\"SYS\": [], \"HUMAN\": [], \"AI\": []\t},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def default_messages() -> Dict[str, Dict[str, List[BaseMessage]]]:\n",
    "\t\"\"\"Tạo dictionary mặc định cho `messages`, giữ nguyên danh sách các Agent.\n",
    "\n",
    "\t- Sử dụng `defaultdict` để tránh lỗi KeyError nếu truy cập Agent chưa tồn tại.\n",
    "\t- `lambda: {\"SYS\": [], \"HUMAN\": [], \"AI\": []}` đảm bảo mỗi Agent có đủ 3 loại tin nhắn.\n",
    "\t- `DEFAULT_AGENTS.copy()` giúp giữ nguyên cấu trúc ban đầu mà không bị ghi đè.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDict[str, Dict[str, List[BaseMessage]]]: Cấu trúc lưu trữ tin nhắn theo Agent và loại tin nhắn.\n",
    "\t\"\"\"\n",
    "\treturn defaultdict(lambda: {\"SYS\": [], \"HUMAN\": [], \"AI\": []}, DEFAULT_AGENTS.copy())\n",
    "\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "\t\"\"\"Manages structured conversation state in a multi-agent system.\n",
    "\n",
    "\tAttributes:\n",
    "\t\thuman_query (List[HumanMessage]): List of user queries.\n",
    "\t\tmessages (Dict[str, Dict[str, List[BaseMessage]]]): \n",
    "\t\t\tStores categorized messages by agent type and message type:\n",
    "\t\t\t- **Agent types**: MANAGER_AGENT, REQUEST_VERIFY, PROMPT_AGENT, DATA_AGENT, MODEL_AGENT, OP_AGENT.\n",
    "\t\t\t- **Message types**: SYSTEM, HUMAN, AI.\n",
    "\t\tis_last_step (bool): Indicates if this is the final step.\n",
    "\t\tremaining_steps (int): Number of steps left.\n",
    "\n",
    "\tMethods:\n",
    "\t\tget_all_msgs(): Retrieves all messages across all agents in chronological order.\n",
    "\t\tget_latest_msg(agent_type, msg_type): Returns the latest message from a given agent and type.\n",
    "\t\tget_msgs_by_agent_type_and_msg_type(agent_type, msg_type): Retrieves all messages from a specific agent and type.\n",
    "\t\tadd_unique_msgs(node, msgs_type, msg): Adds a unique message to a specified node.\n",
    "\t\"\"\"\n",
    "\thuman_query: Annotated[List[HumanMessage], add_messages] = Field(default_factory=list)\n",
    "\tmessages: Dict[str, Dict[str, List[BaseMessage]]] = Field(\n",
    "\t\tdefault_factory=default_messages, \n",
    "\t\tdescription=\"Categorized messages by agent type and message type.\"\n",
    "\t)\n",
    "\tis_last_step: bool = False\n",
    "\tremaining_steps: int = 3\n",
    "\n",
    "\tdef get_all_msgs(self) -> List[BaseMessage]:\n",
    "\t\t\"\"\"Retrieves all messages from all agents in chronological order.\"\"\"\n",
    "\t\tall_messages = []\n",
    "\t\tfor agent_messages in self.messages.values():\n",
    "\t\t\tfor msg_list in agent_messages.values():\n",
    "\t\t\t\tall_messages.extend(msg_list)\n",
    "\t\treturn all_messages\n",
    "\n",
    "\tdef get_latest_msg(self, agent_type: str, msg_type: str) -> BaseMessage:\n",
    "\t\t\"\"\"Returns the latest message from a specified agent and type.\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t\tValueError: If the agent type or message type is invalid.\n",
    "\t\t\"\"\"\n",
    "\t\tif agent_type not in self.messages: raise ValueError(f\"[ERROR]: Invalid agent category '{agent_type}'. Must be one of {list(self.messages.keys())}.\")\n",
    "\t\tif msg_type not in self.messages[agent_type]: raise ValueError(f\"[ERROR]: Invalid message type '{msg_type}'. Must be 'SYSTEM', 'HUMAN', or 'AI'.\")\n",
    "\t\treturn self.messages[agent_type][msg_type][-1] if self.messages[agent_type][msg_type] else None\n",
    "\n",
    "\tdef get_msgs_by_node_and_msgs_type(self, node: str, msgs_type: str) -> List[BaseMessage]:\n",
    "\t\t\"\"\"Retrieves all messages from a specified agent and type.\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t\tValueError: If the node or message type is invalid.\n",
    "\t\t\"\"\"\n",
    "\t\tif node not in self.messages: raise ValueError(f\"[ERROR]: Invalid agent category '{node}'. Must be one of {list(self.messages.keys())}.\")\n",
    "\t\tif msgs_type not in self.messages[node]: raise ValueError(f\"[ERROR]: Invalid message type '{msgs_type}'. Must be 'SYSTEM', 'HUMAN', or 'AI'.\")\n",
    "\t\treturn self.messages[node][msgs_type]\n",
    "\n",
    "\tdef add_unique_msgs(self, node: str, msgs_type: str, msg: BaseMessage) -> None:\n",
    "\t\t\"\"\"Adds a unique message to a specific node in the State.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tnode (str): The agent node (e.g., \"MANAGER_AGENT\", \"REQUEST_VERIFY\").\n",
    "\t\t\tmsgs_type (str): The message type (one of \"AI\", \"HUMAN\", \"SYS\").\n",
    "\t\t\tmsg (BaseMessage): The message object to be stored.\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t\tValueError: If the message type is invalid.\n",
    "\t\t\"\"\"\n",
    "\t\tif node not in self.messages: \n",
    "\t\t\tself.messages[node] = {\"SYS\": [], \"HUMAN\": [], \"AI\": []}\n",
    "\t\tif msgs_type not in {\"SYS\", \"HUMAN\", \"AI\"}: \n",
    "\t\t\traise ValueError(f\"[ERROR]: Invalid message type '{msgs_type}'. Must be 'SYS', 'HUMAN', or 'AI'.\")\n",
    "\t\tif node == \"REQUEST_VERIFY\": \n",
    "\t\t\tself.messages[node][msgs_type] = [msg]\n",
    "\t\telse:\n",
    "\t\t\tif msg.content not in {m.content for m in self.messages[node][msgs_type]}:\n",
    "\t\t\t\tself.messages[node][msgs_type].append(msg)\n",
    "\n",
    "\n",
    "# TODO: Cần thêm prompt để hướng dẫn mô hình trả lời tốt hơn, đề xuất sử dụng chain-of-thought prompt.\n",
    "class Conversation(TypedDict):\n",
    "\t\"\"\"You are an AI assistant. Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "\tresponse:\t\tAnnotated[str, ..., \"A conversational response to the user's query\"\t\t\t]\n",
    "\tjustification: \tAnnotated[str, ..., \"A brief explanation or reasoning behind the response.\"\t]\n",
    "\n",
    "\n",
    "\n",
    "class Prompt2JSON(TypedDict):\n",
    "\t\"\"\"Parses user requirements related to AI project potential into structured JSON.\"\"\"\n",
    "\tproblem_area: \tAnnotated[str, ..., \"Problem domain (e.g., tabular data analysis).\"\t\t\t]\n",
    "\ttask: \t\t\tAnnotated[str, ..., \"Type of ML task (e.g., classification, regression).\"\t]\n",
    "\tapplication: \tAnnotated[str, ..., \"Application field (e.g., agriculture, healthcare).\"\t]\n",
    "\tdataset_name: \tAnnotated[str, ..., \"Dataset name (e.g., banana_quality).\"\t\t\t\t\t]\n",
    "\tdata_modality: \tAnnotated[List[str], ..., \"Data modality (e.g., ['tabular', 'image']).\"\t\t]\n",
    "\tmodel_name: \tAnnotated[str, ..., \"Model name (e.g., XGBoost, ResNet).\"\t\t\t\t\t]\n",
    "\tmodel_type: \tAnnotated[str, ..., \"Model type (e.g., vision, text, tabular).\"\t\t\t\t]\n",
    "\tcuda: \t\t\tAnnotated[bool, ..., \"Requires CUDA? (True/False).\"\t\t\t\t\t\t\t]\n",
    "\tvram: \t\t\tAnnotated[str, ..., \"GPU's VRAM required (e.g., '6GB').\"\t\t\t\t\t]\n",
    "\tcpu_cores: \t\tAnnotated[int, ..., \"Number of CPU cores required.\"\t\t\t\t\t\t\t]\n",
    "\tram: \t\t\tAnnotated[str, ..., \"RAM required (e.g., '16GB').\"\t\t\t\t\t\t\t]\n",
    "\n",
    "\n",
    "\n",
    "MGR_SYS_MSG_PROMPT \t\t\t\t= \tPrompts.AGENT_MANAGER_PROMPT\n",
    "VER_RELEVANCY_MSG_PROMPT \t\t= \tPrompts.REQUEST_VERIFY_RELEVANCY\n",
    "VER_ADEQUACY_MSG_PROMPT \t\t= \tPrompts.REQUEST_VERIFY_ADEQUACY\n",
    "CONVERSATION_2_JSON_MSG_PROMPT \t= \tPrompts.CONVERSATION_TO_JSON_PROMPT\n",
    "PROMPT_2_JSON_SYS_MSG_PROMPT \t= \tPrompts.PROMPT_AGENT_PROMPT\n",
    "\n",
    "\n",
    "\n",
    "CONFIG = {\"configurable\": {\"thread_id\": str(uuid.uuid4()), \"recursion_limit\": 100, \"timeout\": 60}}\n",
    "CHECKPOINTER = MemorySaver()\n",
    "STORE = InMemoryStore()\n",
    "\n",
    "\n",
    "\n",
    "LLM_HTEMP\t=\tChatOllama(model=\"llama3.2:3b-instruct-fp16\", temperature=0.8, num_predict=128_000)\n",
    "LLM_LTEMP \t= \tChatOllama(model=\"llama3.2:3b-instruct-fp16\", temperature=0, num_predict=128_000)\n",
    "\n",
    "LLM_STRUC_OUT_CONVERSATION \t=\tLLM_HTEMP.with_structured_output(schema=Conversation, method=\"json_schema\")\n",
    "LLM_STRUC_OUT_AUTOML \t\t= \tLLM_HTEMP.with_structured_output(schema=Prompt2JSON, method=\"json_schema\")\n",
    "\n",
    "\n",
    "\n",
    "def add_special_token_to_human_query(human_msg: str) -> str:\n",
    "\t\"\"\"Enhances the human query by formatting it with special tokens of LLama 3 series models.\n",
    "\n",
    "\tArgs:\n",
    "\t\thuman_msg (str): User's query.\n",
    "\n",
    "\tReturns:\n",
    "\t\tformatted_query: A formatted human query wrapped with special tokens.\n",
    "\n",
    "\tExample:\n",
    "\t\t>>> state.user_query = [HumanMessage(content=\"What is AI?\")]\n",
    "\t\t>>> enhance_human_query(state)\n",
    "\t\tformatted_query=\"<|start_header_id|>HUMAN<|end_header_id|>What is AI?<|end_of_turn_id|><|start_header_id|>AI<|end_header_id|>\"\n",
    "\t\"\"\"\n",
    "\tformatted_query = (\n",
    "\t\tf\"{START_HEADER_ID}HUMAN{END_HEADER_ID}\"\n",
    "\t\tf\"{human_msg}{END_OF_TURN_ID}\"\n",
    "\t\tf\"{START_HEADER_ID}AI{END_HEADER_ID}\"\n",
    "\t)\n",
    "\treturn formatted_query\n",
    "\n",
    "\n",
    "\n",
    "def add_eotext_eoturn_to_ai_msg(ai_msg: AIMessage, end_of_turn_id_token: str = END_OF_TURN_ID, end_of_text_token: str = END_OF_TEXT) -> AIMessage:\n",
    "\t\"\"\"Ensures AIMessage content ends with required special tokens.\n",
    "\n",
    "\tThis function appends `<|end_of_text|>` and `<|eot_id|>` at the end of the message content if they are not already present.\n",
    "\n",
    "\tArgs:\n",
    "\t\tai_msg (AIMessage): The AI-generated message.\n",
    "\t\tend_of_text_token (str, optional) = \"<|end_of_text|>\": Special token indicating the end of the text.\n",
    "\t\tend_of_turn_id_token (str, optional) = \"<|eot_id|>\": Special token marking the end of a conversation turn.\n",
    "\n",
    "\tReturns:\n",
    "\t\tAIMessage: The updated AI message with the required tokens.\n",
    "\n",
    "\tExample:\n",
    "\t\t>>> message = AIMessage(content=\"Hello, how can I assist you?\")\n",
    "\t\t>>> add_eotext_eoturn_to_ai_msg(message, \"<|end_of_text|>\", \"<|eot_id|>\")\n",
    "\t\tAIMessage(content=\"Hello, how can I assist you?<|end_of_text|><|eot_id|>\")\n",
    "\t\"\"\"\n",
    "\tcontent = ai_msg.content.strip()\n",
    "\tif not content.endswith(end_of_turn_id_token): content += end_of_turn_id_token\n",
    "\tif not content.endswith(end_of_turn_id_token + end_of_text_token): content = content.replace(end_of_turn_id_token, end_of_turn_id_token + end_of_text_token)\n",
    "\treturn AIMessage(content=content)\n",
    "\n",
    "\n",
    "# TODO: Tối ưu hàm này, cần loại bỏ `.get()` tránh tạo đối tượng không cần thiết.\n",
    "def build_react_sys_msg_prompt(tool_desc_prompt: str, react_prompt: str, tools: List[BaseTool]) -> str:\n",
    "\t\"\"\"Builds a formatted system prompt with tool descriptions.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttool_desc_prompt (PromptTemplate): Template for tool descriptions.\n",
    "\t\treact_prompt (PromptTemplate): Template for constructing the final system prompt.\n",
    "\t\ttools (List[BaseTool]): List of tool objects.\n",
    "\n",
    "\tReturns:\n",
    "\t\tstr: A fully formatted system prompt with tool descriptions.\n",
    "\t\"\"\"\n",
    "\tlist_tool_desc = [\n",
    "\t\ttool_desc_prompt.format(\n",
    "\t\t\tname_for_model=(tool_info := getattr(tool.args_schema, \"model_json_schema\", lambda: {})()).get(\"title\", \"Unknown Tool\"),\n",
    "\t\t\tname_for_human=tool_info.get(\"title\", \"Unknown Tool\"),\n",
    "\t\t\tdescription_for_model=tool_info.get(\"description\", \"No description available.\"),\n",
    "\t\t\ttype=tool_info.get(\"type\", \"N/A\"),\n",
    "\t\t\tproperties=json.dumps(tool_info.get(\"properties\", {}), ensure_ascii=False),\n",
    "\t\t\trequired=json.dumps(tool_info.get(\"required\", []), ensure_ascii=False),\n",
    "\t\t) + \" Format the arguments as a JSON object.\"\n",
    "\t\tfor tool in tools\n",
    "\t]\n",
    "\tprompt = react_prompt.format(\n",
    "\t\tBEGIN_OF_TEXT=BEGIN_OF_TEXT, \n",
    "\t\tSTART_HEADER_ID=START_HEADER_ID, \n",
    "\t\tEND_HEADER_ID=END_HEADER_ID, \n",
    "\t\tEND_OF_TURN_ID=END_OF_TURN_ID, \n",
    "\t\ttools_desc=\"\\n\\n\".join(list_tool_desc), \n",
    "\t\ttools_name=\", \".join(tool.name for tool in tools)\n",
    "\t)\n",
    "\treturn prompt\n",
    "\n",
    "\n",
    "\n",
    "def conversation2json(msg_prompt: str, llm_structure_output: Runnable[LanguageModelInput, Dict | BaseModel], human_msg: HumanMessage, schema: Type[Dict]) -> json:\n",
    "\t\"\"\"Parses user's query into structured JSON for manager_agent.\n",
    "\n",
    "\tArgs:\n",
    "\t\tllm_structure_output (Runnable[LanguageModelInput, Dict | BaseModel]): LLM function to generate structured output.\n",
    "\t\thuman_msg (HumanMessage): User's input message.\n",
    "\t\tschema (Type[Dict]): TypedDict schema to validate JSON.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDict: Validated JSON containing:\n",
    "\t\t\t{\n",
    "\t\t\t\t\"response\": \"A conversational response to the user's query.\",\n",
    "\t\t\t\t\"justification\": \"A brief explanation or reasoning behind the response.\"\n",
    "\t\t\t}\n",
    "\n",
    "\tRaises:\n",
    "\t\tValueError: If the response does not contain valid JSON or is missing required fields.\n",
    "\t\"\"\"\n",
    "\tjson_data = llm_structure_output.invoke([human_msg])\n",
    "\tif not json_data:\n",
    "\t\tjson_schema = json.dumps(TypeAdapter(schema).json_schema()[\"properties\"], indent=2).strip()\n",
    "\t\tsys_msg = SystemMessage(content=msg_prompt.format(\n",
    "\t\t\tBEGIN_OF_TEXT=BEGIN_OF_TEXT, \n",
    "\t\t\tSTART_HEADER_ID=START_HEADER_ID, \n",
    "\t\t\tEND_HEADER_ID=END_HEADER_ID, \n",
    "\t\t\tjson_schema=json_schema, \n",
    "\t\t\thuman_msg=human_msg.content, \n",
    "\t\t\tEND_OF_TURN_ID=END_OF_TURN_ID\n",
    "\t\t))\n",
    "\t\tai_msg_json = LLM_LTEMP.invoke([sys_msg])\n",
    "\t\tpattern = r\"```json\\n(.*?)\\n```\"\n",
    "\t\tmatch = re.search(pattern=pattern, string=ai_msg_json.content, flags=re.DOTALL)\n",
    "\t\tif not match: raise ValueError(\">>> Không tìm thấy JSON hợp lệ trong phản hồi của mô hình.\")\n",
    "\t\tjson_string = match.group(1).strip()\n",
    "\t\ttry:\n",
    "\t\t\tjson_data = json.loads(json_string)\n",
    "\t\t\tif DEBUG: \n",
    "\t\t\t\tprint(\">>> JSON hợp lệ:\")\n",
    "\t\t\t\tprint(json.dumps(json_data, indent=2, ensure_ascii=False))\n",
    "\t\texcept json.JSONDecodeError as e:\n",
    "\t\t\traise ValueError(f\">>> JSON không hợp lệ (DecodeError): {e}\")\n",
    "\tmissing_keys = set(schema.__annotations__.keys()) - json_data.keys()\n",
    "\textra_keys = json_data.keys() - set(schema.__annotations__.keys())\n",
    "\tif missing_keys: raise ValueError(f\">>> JSON thiếu các trường bắt buộc: {missing_keys}\")\n",
    "\tif extra_keys: raise ValueError(f\">>> JSON có các trường không hợp lệ: {extra_keys}\")\n",
    "\treturn json_data\n",
    "\n",
    "\n",
    "\n",
    "def manager_agent(state: State) -> State:\n",
    "\t\"\"\"Manager Agent.\n",
    "\n",
    "\tExample:\n",
    "\t\t>>> Human query: I need a very accurate model to classify images in the \n",
    "\t\t\t\tButterfly Image Classification dataset into their respective \n",
    "\t\t\t\tcategories. The dataset has been uploaded with its label \n",
    "\t\t\t\tinformation in the labels.csv file.\n",
    "\t\t>>> AI response: Here is a sample code that uses the Keras library to develop and train a convolutional neural network (CNN) model for ...\n",
    "\t\"\"\"\n",
    "\tsys_msg = SystemMessage(content=MGR_SYS_MSG_PROMPT.format(\n",
    "\t\t\tBEGIN_OF_TEXT=BEGIN_OF_TEXT, \n",
    "\t\t\tSTART_HEADER_ID=START_HEADER_ID, \n",
    "\t\t\tEND_HEADER_ID=END_HEADER_ID, \n",
    "\t\t\tEND_OF_TURN_ID=END_OF_TURN_ID\n",
    "\t\t))\n",
    "\thuman_msg = HumanMessage(content=add_special_token_to_human_query(human_msg=state.human_query[-1].content if state.human_query else \"\"))\n",
    "\thuman_msg_json = HumanMessage(json.dumps((conversation2json(\n",
    "\t\t\tmsg_prompt=CONVERSATION_2_JSON_MSG_PROMPT, \n",
    "\t\t\tllm_structure_output=LLM_STRUC_OUT_CONVERSATION, \n",
    "\t\t\thuman_msg=human_msg, schema=Conversation\n",
    "\t\t)), indent=2\n",
    "\t))\n",
    "\tai_msg = LLM_LTEMP.invoke([sys_msg, human_msg, human_msg_json])\n",
    "\tif not isinstance(ai_msg, AIMessage): \n",
    "\t\tai_msg = AIMessage(\n",
    "\t\t\tcontent=ai_msg.strip() \n",
    "\t\t\tif isinstance(ai_msg, str) \n",
    "\t\t\telse \"At node_manager_agent, I'm unable to generate a response.\"\n",
    "\t\t)\n",
    "\tai_msg = add_eotext_eoturn_to_ai_msg(ai_msg=ai_msg, end_of_turn_id_token=END_OF_TURN_ID, end_of_text_token=END_OF_TEXT)\n",
    "\tstate.add_unique_msgs(node=\"MANAGER_AGENT\", msgs_type=\"SYS\", msg=sys_msg)\n",
    "\tstate.add_unique_msgs(node=\"MANAGER_AGENT\", msgs_type=\"HUMAN\", msg=human_msg)\n",
    "\tstate.add_unique_msgs(node=\"MANAGER_AGENT\", msgs_type=\"AI\", msg=AIMessage(\"<|parse_json|>\" + human_msg_json.content + \"<|end_parse_json|>\" + ai_msg.content))\n",
    "\treturn state\n",
    "\n",
    "\n",
    "\n",
    "def check_contain_yes_or_no(ai_msg: str) -> str:\n",
    "\t\"\"\"Checks if the AI response contains 'Yes' or 'No'.\"\"\"\n",
    "\tpattern = r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>\\s*\\n\\s*(yes|no)\\b\"\n",
    "\tmatch = re.search(pattern=pattern, string=ai_msg, flags=re.IGNORECASE)\n",
    "\tif match:return match.group(1).upper()\n",
    "\telse:return \"[ERROR]: Không tìm thấy 'Yes' hoặc 'No' trong phản hồi AI!\"\n",
    "\n",
    "\n",
    "\n",
    "def relevancy(state: State) -> List[BaseMessage]:\n",
    "\t\"\"\"Check request verification-relevancy of human_query.\"\"\"\n",
    "\thuman_msg = state.human_query[-1]\n",
    "\tsys_msg = SystemMessage(content=VER_RELEVANCY_MSG_PROMPT.format(\n",
    "\t\tinstruction=human_msg.content, \n",
    "\t\tBEGIN_OF_TEXT=BEGIN_OF_TEXT, \n",
    "\t\tSTART_HEADER_ID=START_HEADER_ID, \n",
    "\t\tEND_HEADER_ID=END_HEADER_ID, \n",
    "\t\tEND_OF_TURN_ID=END_OF_TURN_ID\n",
    "\t))\n",
    "\tai_msg = LLM_LTEMP.invoke([sys_msg])\n",
    "\tif not isinstance(ai_msg, AIMessage): ai_msg = AIMessage(content=ai_msg.strip() if isinstance(ai_msg, str) else \"At node_request_verify-REQUEST_VERIFY_RELEVANCY, I'm unable to generate a response.\")\n",
    "\tai_msg = add_eotext_eoturn_to_ai_msg(ai_msg=ai_msg, end_of_turn_id_token=END_OF_TURN_ID, end_of_text_token=END_OF_TEXT)\n",
    "\treturn [sys_msg, human_msg, ai_msg]\n",
    "\n",
    "\n",
    "\n",
    "def adequacy(state: State) -> List[BaseMessage]:\n",
    "\t\"\"\"Check request verification-adequacy of AIMessage response with JSON object.\"\"\"\n",
    "\tpattern = r\"<\\|parse_json\\|>(.*?)<\\|end_parse_json\\|>\"\n",
    "\thuman_msg = state.messages['MANAGER_AGENT']['HUMAN'][-1]\n",
    "\tai_msg = state.messages['MANAGER_AGENT']['AI'][-1]\n",
    "\tjson_obj_from_ai_msg = re.findall(pattern=pattern, string=ai_msg.content, flags=re.DOTALL)[-1]\n",
    "\tsys_msg = SystemMessage(content=VER_ADEQUACY_MSG_PROMPT.format(\n",
    "\t\tBEGIN_OF_TEXT=BEGIN_OF_TEXT, \n",
    "\t\tSTART_HEADER_ID=START_HEADER_ID, \n",
    "\t\tEND_HEADER_ID=END_HEADER_ID, \n",
    "\t\tparsed_user_requirements=json_obj_from_ai_msg, \n",
    "\t\tEND_OF_TURN_ID=END_OF_TURN_ID\n",
    "\t))\n",
    "\tai_msg = LLM_LTEMP.invoke([sys_msg])\n",
    "\tif not isinstance(ai_msg, AIMessage): ai_msg = AIMessage(content=ai_msg.strip() if isinstance(ai_msg, str) else \"At node_request_verify-REQUEST_VERIFY_ADEQUACY, I'm unable to generate a response.\")\n",
    "\tai_msg = add_eotext_eoturn_to_ai_msg(ai_msg=ai_msg, end_of_turn_id_token=END_OF_TURN_ID, end_of_text_token=END_OF_TEXT)\n",
    "\treturn [sys_msg, human_msg, ai_msg]\n",
    "\n",
    "\n",
    "\n",
    "def request_verify(state: State) -> State:\n",
    "\t\"\"\"Request verification output of Agent Manager.\"\"\"\n",
    "\tai_msg_relevancy = relevancy(state=state)[2]\n",
    "\tai_msg_adequacy = adequacy(state=state)[2]\n",
    "\tyes_no_relevancy = check_contain_yes_or_no(ai_msg=ai_msg_relevancy.content)\n",
    "\tyes_no_adequacy  = check_contain_yes_or_no(ai_msg=ai_msg_adequacy.content )\n",
    "\tyes_no = \"YES\" if \"YES\" in (yes_no_relevancy, yes_no_adequacy) else \"NO\"\n",
    "\tai_msg = AIMessage(content=yes_no)\n",
    "\tstate.add_unique_msgs(node=\"REQUEST_VERIFY\", msgs_type=\"AI\", msg=ai_msg)\n",
    "\treturn state\n",
    "\n",
    "\n",
    "\n",
    "def req_ver_yes_or_no_control_flow(state: State) -> State:\n",
    "\t\"\"\"Determines the next step based on the AI response from REQUEST_VERIFY.\n",
    "\n",
    "\tArgs:\n",
    "\t\tstate (State): The current conversation state.\n",
    "\n",
    "\tReturns:\n",
    "\t\tstr: The next agent (\"PROMPT_AGENT\" or END).\n",
    "\n",
    "\tRaises:\n",
    "\t\tValueError: If there is no valid AI response or an unexpected response.\n",
    "\t\"\"\"\n",
    "\tif \"REQUEST_VERIFY\" not in state.messages or \"AI\" not in state.messages[\"REQUEST_VERIFY\"]:\n",
    "\t\traise ValueError(\"[ERROR]: No AI message found in REQUEST_VERIFY.\")\n",
    "\tai_msgs = state.messages[\"REQUEST_VERIFY\"][\"AI\"]\n",
    "\tif not ai_msgs:\n",
    "\t\traise ValueError(\"[ERROR]: AI message list is empty in REQUEST_VERIFY.\")\n",
    "\tai_msg = ai_msgs[-1]\n",
    "\tif not hasattr(ai_msg, \"content\"):\n",
    "\t\traise ValueError(\"[ERROR]: AI message has no content.\")\n",
    "\tresp = ai_msg.content.strip().upper()\n",
    "\tnext_step_map = {\"YES\": \"PROMPT_AGENT\", \"NO\": END}\n",
    "\tif resp in next_step_map:\n",
    "\t\treturn next_step_map[resp]\n",
    "\traise ValueError(f\">>> [ERROR]: Unexpected response '{resp}'\")\n",
    "\n",
    "\n",
    "\n",
    "def prompt_agent(state: State) -> State:\n",
    "\t\"\"\"Prompt Agent parses user's requirements into JSON following a TypedDict schema.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tstate (State): The current state of the conversation.\n",
    "\n",
    "\tReturns:\n",
    "\t\tState: Updated state with the parsed JSON response.\n",
    "\t\"\"\"\n",
    "\tif \"MANAGER_AGENT\" not in state.messages or \"HUMAN\" not in state.messages[\"MANAGER_AGENT\"]:\n",
    "\t\traise ValueError(\"[ERROR]: No HUMAN messages found in MANAGER_AGENT.\")\n",
    "\thuman_msg = state.messages[\"MANAGER_AGENT\"][\"HUMAN\"][-1]\n",
    "\tparsed_json = conversation2json(\n",
    "\t\tmsg_prompt=PROMPT_2_JSON_SYS_MSG_PROMPT, \n",
    "\t\tllm_structure_output=LLM_STRUC_OUT_AUTOML,\n",
    "\t\thuman_msg=human_msg,\n",
    "\t\tschema=Prompt2JSON\n",
    "\t)\n",
    "\texpected_keys, received_keys = set(Prompt2JSON.__annotations__), set(parsed_json)\n",
    "\tif missing_keys := expected_keys - received_keys: \n",
    "\t\traise ValueError(f\"[ERROR]: JSON thiếu các trường bắt buộc: {missing_keys}\")\n",
    "\tif extra_keys := received_keys - expected_keys: \n",
    "\t\traise ValueError(f\"[ERROR]: JSON có các trường không hợp lệ: {extra_keys}\")\n",
    "\tai_msg_json = AIMessage(content=json.dumps(parsed_json, indent=2))\n",
    "\tai_msg_json = add_eotext_eoturn_to_ai_msg(ai_msg=ai_msg_json, end_of_turn_id_token=END_OF_TURN_ID, end_of_text_token=END_OF_TEXT)\n",
    "\tstate.add_unique_msgs(node=\"PROMPT_AGENT\", msgs_type=\"AI\", msg=ai_msg_json)\n",
    "\treturn state\n",
    "\n",
    "\n",
    "\n",
    "def rap_agent(state: State) -> State:\n",
    "\t\"Retrieval-Augmented Planning Agent.\"\n",
    "\treturn state\n",
    "\n",
    "\n",
    "\n",
    "def data_agent(state: State) -> State:\n",
    "\t\"Data Agent.\"\n",
    "\treturn state\n",
    "\n",
    "\n",
    "\n",
    "def model_agent(state: State) -> State:\n",
    "\t\"Model Agent.\"\n",
    "\treturn state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"MANAGER_AGENT\", manager_agent)\n",
    "workflow.add_node(\"REQUEST_VERIFY\", request_verify)\n",
    "workflow.add_node(\"PROMPT_AGENT\", prompt_agent)\n",
    "workflow.add_node(\"RETRIEVAL_AUGMENTED_PLANNING\", rap_agent)\n",
    "workflow.add_node(\"DATA_AGENT\", data_agent)\n",
    "workflow.add_node(\"MODEL_AGENT\", model_agent)\n",
    "\n",
    "workflow.add_edge(START, \"MANAGER_AGENT\")\n",
    "workflow.add_edge(\"MANAGER_AGENT\", \"REQUEST_VERIFY\")\n",
    "workflow.add_conditional_edges(\"REQUEST_VERIFY\", req_ver_yes_or_no_control_flow, [\"PROMPT_AGENT\", END])\n",
    "workflow.add_edge(\"PROMPT_AGENT\", \"RETRIEVAL_AUGMENTED_PLANNING\")\n",
    "workflow.add_edge(\"RETRIEVAL_AUGMENTED_PLANNING\", \"DATA_AGENT\")\n",
    "workflow.add_edge(\"RETRIEVAL_AUGMENTED_PLANNING\", \"MODEL_AGENT\")\n",
    "workflow.add_edge(\"DATA_AGENT\", \"MODEL_AGENT\")\n",
    "workflow.add_edge(\"MODEL_AGENT\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=CHECKPOINTER, store=STORE, debug=DEBUG, name=NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/urllib3/connectionpool.py:367\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CurveStyle, MermaidDrawMethod, NodeStyles\n\u001b[1;32m      4\u001b[0m display(\n\u001b[1;32m      5\u001b[0m     Image(\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/langchain_core/runnables/graph.py:630\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[1;32m    625\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[1;32m    626\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[1;32m    627\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[1;32m    628\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[1;32m    629\u001b[0m )\n\u001b[0;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:214\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[0m\n\u001b[1;32m    208\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    209\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[1;32m    210\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     )\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[0;32m--> 214\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:336\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[0m\n\u001b[1;32m    330\u001b[0m         background_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m image_url \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmermaid_syntax_encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&bgColor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    338\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.11/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
